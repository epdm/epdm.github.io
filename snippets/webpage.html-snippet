<h2 id="definition-of-quality">Definition of Quality</h2>
<p><strong>Quality</strong> is a somewhat abstract, subjective quality with people interpreting it differently. Like the 'theory of relativity' quality is expressed as a relative concept and can be different things to different people. For example:</p>
<p><em>&quot;A Rolls Royce car is a quality car for certain customers whereas a VW Beatle can be quality car for other customers.&quot;</em></p>
<p>Therefore, consumers may tend to focus on the eventual specification quality of a product/service, or how it compares with the competing companies in the marketplace. However, on the contrary, producers might measure the conformance quality, or the degree to which the product/service was produced correctly. The producer of a product may focus on process variation minimisation, to achieve uniformity amongst and between batches.</p>
<p>Five discrete and interrelated definitions of quality are listed below (Garvin, 1988):</p>
<ul>
<li>Transcendent (excellence);</li>
<li>Product-based (amount of desireable attribute);</li>
<li>User-based (fitness for use);</li>
<li>Manufacturing-based (conformance to specification);</li>
<li>Value-based (satisfaction relative to price);</li>
</ul>
<h2 id="six-sigma">Six Sigma</h2>
<p>Six sigma represents a set of techniques/tools for implementing process improvement. This improvement is achieved through identifying and subsequently removing the causes of defects, thus minimising variability in manufacturing and business processes. A six sigma process is ome in wich 99.99966% of all opportunities to produce some feature or part are statistically expected to be free of defects (3.4 defective features per million opportunities). A defect in this sense can be defined as any variation of a required characteristic of the product for its parts, which is far enough removed from its nominal value to precent the product from fulfilling the physical and functional requirements of the customer.</p>
<p>Normal distribution curves (<strong>Figure 1</strong>) are symmetrical about the mean value (μ), with the total area under the curve equating to one. If a process is classified as 3 sigma, 99.7% of outputs are defect free. Mean is the central tendency of the process, or the average of all values within the population. The standard deviation (σ) is a measure of dispersion or variability.</p>
<img src="images/Six%20Sigma.png" title="Six Sigma" />
<center>
<strong>Figure 1</strong>: A normal distribution curve, with the standard deviations from the mean marked.
</center>
<p>The upper specification limit (USL) and the lower specification limit (LSL) set permissible limits for the process variation. For example, the USL and LSL of a process may be set at 3 and -3, thus yielding a process which is 99.7% defect free. USL represents a value designating an upper limit above which the process or characteristic performance is unacceptable. In the converse case, the LSL represents a value designating a lower limit, below which the process or characteristic performance is unacceptable.</p>
<p>The relationship between yield, variability and specification limits is that essentially the specification limits provide the permissible process variations. Minimising variability therefore inherently leads to a better yield, as the probability of defects occurring is substantially mitigated. Cp and Cpk represent metrics of process quality. Cp is a measure of how capable the process is of producing the required process characteristic. Cp is known as the capability index, or design margin, and is calculated using the following:</p>
<div class="figure">
<img src="images/CpCalculation.png" title="Calculating Process Capability" />

</div>
<p>Cpk is a measure of actual performance which takes the actual mean into account. Cpk is equal to Cp when the process mean is equal to the target, or nominal value. Cpk essentially accounts for the process mean not hitting the target value. The following calculations can be used to determine Cpk.</p>
<div class="figure">
<img src="images/CpkCalculation.png" title="Calculating Cpk" />

</div>
<div class="figure">
<img src="images/Cpk.png" title="Calculating Cpk" />

</div>
<div class="figure">
<img src="images/KCalculation.png" title="Calculating K Value" />

</div>
<p>Poisson distribution describes the probability distribution of an event occurring with respect to time, or space. The eventual process yield can be calculated using Poisson's formula using the following, where dpu is the measured defects per unit.</p>
<div class="figure">
<img src="images/PoissonsDistribution.png" title="Poisson Distribution" />

</div>
<p>As an example if average dpu=1, the probability of having a device with no defects can be calculated as:</p>
<div class="figure">
<img src="images/Yield.png" title="Yield Calculation" />

</div>
<h2 id="relationship-between-quality-and-reliability">Relationship Between Quality and Reliability</h2>
<p>Quality assures the product will work after assembly, whereas reliability provides the probability that the design will perform its intended function for a designated period of time under specified conditions. Engineering process reliability is the fundamental concept that is meant to anticipate quality failures over the life cycle of a product. Variation of the process output may affect both quality and reliability.</p>
<p>Controlling reliability is much more complex and cannot be controlled by a standard &quot;quality&quot; (Six Sigma) approach, as they need a systems engineering approach. Quality is a snapshot at the start of life and mainly related to control of lower level product specifications and reliability is (as part of systems engineering) more of a system level motion picture of the day-by-day operation for many years. Time zero defects are manufacturing mistakes that escaped quality control, whereas, the additionald effects that appear over time are 'reliability defects'.</p>
<h2 id="impact-of-quality-on-cycle-time-and-cost">Impact of Quality on Cycle Time and Cost</h2>
<p>These three project managment constraints are traditionally represented in what is known as the &quot;Iron Triangle&quot;, depicted in the <strong>Figure 2</strong>.</p>
<img src="images/iron_triangle.jpg" title="The Iron Triangle" />
<center>
<strong>Figure 2</strong>: The Iron Triagle.
</center>
<p>The relationship between the three constraints means that management staff end up having to make a choice between two out of the three of them; in other words, &quot;Pick any two&quot;. This usually ends up with the three following options:</p>
<ul>
<li>Designing a product to a high standard with a low time to market, at the cost of being expensive</li>
<li>Designing a product quickly and at a low cost, at the expense of the product quality</li>
<li>Designing a product to a high standard and at a low cost, but taking a long time to market.</li>
</ul>
<h2 id="iso-9000">ISO 9000</h2>
<p>The ISO 9000 is family of standards that gives requirements for an organization's quality management system (QMS). It can be adopted to help ensure organisations meet the standards of customers and stakeholders whilst meeting the statutory and regulatory requirements of products. ISO 9000 is based on the following eight quality management principles:</p>
<ol style="list-style-type: decimal">
<li>Customer focus</li>
<li>Leadership</li>
<li>Involvement of people</li>
<li>Process approach</li>
<li>System approach to management</li>
<li>Continual improvement</li>
<li>Factual approach to decision making</li>
<li>Mutually beneficial supplier relationships</li>
</ol>
<p>Global adoption of the ISO 9000 standard is growing annually - the number of global ISO certified organisations recorded in the world by the end of 2014 was 1,138,155, up from 409,421 by the end of 2000. The reason for the global adoption can be attributed to a number of the following reasons:</p>
<ol style="list-style-type: decimal">
<li>Creates a more efficient, effective operation</li>
<li>Increases customer satisfaction and retention</li>
<li>Reduces audits</li>
<li>Enhances marketing</li>
<li>Improves employee motivation, awareness, and morale</li>
<li>Promotes international trade</li>
<li>Increases profit</li>
<li>Reduces waste and increases productivity</li>
<li>Common tool for standardization</li>
</ol>
<p>A range of Case Studies (ISO 9000 Case Studies, 2016) can be viewed to support the claims made.</p>
<h2 id="check-sheets">Check Sheets</h2>
<p>A check sheet is a form used to collect data in real time at the location where the data is generated. A simple example of a check sheet is presented below.</p>
<div class="figure">
<img src="images/CheckSheet1.png" title="Simple Check Sheet" />

</div>
<p>The pertinent advantages of utilising check sheets for gathering data are as follows:</p>
<ol style="list-style-type: decimal">
<li>They are a quick, very easy and efficient means for recording desired information.</li>
<li>Information gathered can be either qualitative or quantitative.</li>
</ol>
<p>Check sheets are generally be used to:</p>
<ol style="list-style-type: decimal">
<li>Quantify defects by type, location, and cause (e.g. from a machine or worker)</li>
<li>Keep track of the completion of steps in a multi-step procedure (i.e. be used as a checklist)</li>
<li>Check the shape of the probability distribution of a process.</li>
</ol>
<h2 id="pareto">Pareto</h2>
<p>The Pareto principle (also known as the 80 - 20 rule, the law of the vital few, and the principle of factor sparsity) states that, for many events, roughly 80% of the effects come from 20% of the causes. The term 80 - 20 is only a shorthand for the general principle at work. In individual cases, the distribution could just as well be, say, 80 - 10 or 80 -30. There is no need for the two numbers to add up to the number 100, as they are measures of different things. A simple example of a pareto chart is presented below.</p>
<div class="figure">
<img src="images/pareto_chart.png" title="Pareto Chart" />

</div>
<p>Adding up to 100 leads to a nice symmetry. For example, if 80% of effects come from the top 20% of sources, then the remaining 20% of effects come from the lower 80% of sources. This is called the &quot;joint ratio&quot;, and can be used to measure the degree of imbalance: a joint ratio of 96:4 is very imbalanced, 80:20 is significantly imbalanced, 70:30 is moderately imbalanced (Gini index: 40%), and 55:45 is just slightly imbalanced.</p>
<p>This principle is particularly prominent in the field of Software Engineering, as highlighted by the following examples:</p>
<p>Microsoft noted that by fixing the top 20% of the most-reported bugs, 80% of the related errors and crashes in a given system would be eliminated.</p>
<p>In load testing, it is common practice to estimate that 80% of the traffic occurs during 20% of the time.</p>
<p>In Software Engineering, Lowell Arthur expressed a corollary principle: &quot;20 percent of the code has 80 percent of the errors. Find them, fix them!&quot;</p>
<h2 id="fishbone-ishikawa-diagrams">Fishbone Ishikawa Diagrams</h2>
<p>Ishikawa diagrams (also called fishbone diagrams) are causal diagrams that show the causes of a specific event. Common uses of the Ishikawa diagram are product design and quality defect prevention to identify potential factors causing an overall effect. Each cause or reason for imperfection is a source of variation. Causes are usually grouped into major categories to identify these sources of variation. The categories typically include:</p>
<ul>
<li>People: Anyone involved with the process</li>
<li>Methods: How the process is performed and the specific requirements for doing it, such as policies, procedures, rules, regulations and laws</li>
<li>Machines: Any equipment, computers, tools, etc. required to accomplish the job</li>
<li>Materials: Raw materials, parts, pens, paper, etc. used to produce the final product</li>
<li>Measurements: Data generated from the process that are used to evaluate its quality</li>
<li>Environment: The conditions, such as location, time, temperature, and culture in which the process operates</li>
</ul>
<p>A typical, simplistic example of an Ishikawa diagram is presented below:</p>
<div class="figure">
<img src="images/FishBoneDiagram.gif" title="Basketball Free-Throws Fish Bone Diagram" />

</div>
<p>There have been identified topics for fishbone diagram cause classes in different areas of development. They are grouped into easily remembered sets, examples of which are presented below.</p>
<ul>
<li>The 5 M's (used in manufacturing industry):
<ul>
<li>Machine (technology)</li>
<li>Method (process)</li>
<li>Material (Includes Raw Material, Consumables and Information)</li>
<li>Man/mind Power (physical work)</li>
<li>Measurement (Inspection)</li>
</ul></li>
<li>The 8 P's (primarily used in service marketing industry):
<ul>
<li>Product/Service</li>
<li>Price</li>
<li>Place</li>
<li>Promotion</li>
<li>People/personnel</li>
<li>Process</li>
<li>Physical Evidence</li>
<li>Publicity</li>
</ul></li>
<li>The 4 S's (used in service industry):
<ul>
<li>Surroundings</li>
<li>Suppliers</li>
<li>Systems</li>
<li>Skills</li>
</ul></li>
</ul>
<h2 id="cause-screening">Cause Screening</h2>
<p>Screening can be used to eliminate brainstorming and hypothesizing at the beginning of a project. The project team first makes non-invasive observations of the operation. They ignore everything in the middle, and only compare examples of the very best and very worst outputs, searching for consistent differences.</p>
<p>The guidelines are simple:</p>
<ul>
<li>Any factor that is consistently different when the best and worst outputs occur is deemed critical, and the team pursues it.</li>
<li>Any factor that is not consistently different is deemed non-critical, and the team ignores it.</li>
</ul>
<p>With this screening process, practitioners non-invasively observe and review data from the existing operation, and are usually able to separate the critical and non-critical factors more quickly than with the traditional trial-and-error approach.</p>
<h2 id="teamwork">Teamwork</h2>
<p>Teamwork should encompass the following:</p>
<ul>
<li>Knowledge</li>
<li>Design</li>
<li>Redesign</li>
</ul>
<p>Teamwork is someting that requires training. Product owners should not delegate and control every aspect, as this can stifle teamwork and involvement. Constant improvement is the responsibility of managers. Most causes of low quality and productivity are due to issues at this level. An internal consultant can be hired to reslove teamwork issues.</p>
<p>Aspects related to Teamwork involve:</p>
<ul>
<li>Collaboration</li>
<li>Communication, (intra or inter departmental)</li>
<li>Involvement</li>
<li>Training teamwork, along with tools and techniques of quality control, and philosophy of quality culture</li>
</ul>
<div class="figure">
<img src="images/teamwork-1.png" title="Kondo Pillars" />

</div>
<h2 id="multi-voting">Multi-voting</h2>
<p>Allow a group to narrow down a list of options into a manageable size for further consideration. Useful for initiating a selection process after brainstorming. Multivoting is a group decision-making technique used to reduce a long list of items to a manageable number by means of a structured series of votes. The result is a short list identifying what is important to the team.</p>
<p>Sometimes referred to as <code>N/3</code> voting - for N options, each member of the group selects <code>N/3</code> of the options as a means for partial-ordering the options by importance.</p>
<p>Multivoting Procedures * Step 1 - Work from a large list * Step 2 - Assign letter to each item * Step 3 - Vote * Step 4 - Tally the votes * Step 5 - Repeat</p>
<p>Multivoting Rule of Thumb * Number on Team - Eliminate items with * 5 or fewer - 0, 1, or 2 votes * 6 to 15 - 3 or fewer votes * more than 15 - 4 or fewer votes</p>
<h2 id="statistical-process-control">Statistical Process Control</h2>
<p>Initially developed during the second world war. Uses a process of (physical) inspection to separate good products from bad.</p>
<ul>
<li>Developing control charts: a production process is in statistical control if the chart's measurements vary (randomly in some distribution) within the control limits</li>
<li>Accepting sampling methods</li>
</ul>
<p>The achievement of quality should not be considered as separate from the achievement of production.</p>
<p>Identify product that is beyond reasonable quality control by many (3?) standard deviations. This product has been produced by unusual circumstances - and that should be traced and eliminated.</p>
<p>Argument: quality is conformance to requirement and can only be measured by the cost of non-conformance.</p>
<h2 id="taguchi">Taguchi</h2>
<p>The Taguchi approach to Design of Experiments (DoE) necessitates the use of orthogonal arrays to implement fractional factorial experiments. Orthogonal in this sense essentially states that</p>
<p>A range of Taguchi Orthogonal Arrays is available for reference.</p>
<p>Taguchi defines quality as the loss imparted by the product to society from the time the product is shipped. Quality loss occurs when a product deviates from target or nominal values.</p>
<p>Statistical methods developed to improve the quality of manufactures goods. Three principal contributions to statistics:</p>
<ol style="list-style-type: decimal">
<li>Specific loss function <code>L(x) = k(x-N)2</code></li>
<li>The philosophy of off-line quality control</li>
<li>Innovation in the design of experiments</li>
</ol>
<p>Taguchi believed the best opportunity to eliminate variation is during the design of a product and its manufacturing process. Therefore he developed a strategy for quality engineering. There are 3 stages:</p>
<ol style="list-style-type: decimal">
<li>System Design - Conceptual level</li>
<li>Parameter (measure) design - nominal values of the various dimensions and design parameters need to be set. Robustification.</li>
<li>Tolerance design - With a successfully completed parameter design, and an understanding of the effect that the various parameters have on performance, resources can be focused on reducing and controlling variation in the critical few dimensions.</li>
</ol>
<p>TAGUCHI ON QUALITY: Quality has been defined by many as; &quot;being within specifications,&quot; &quot;zero defects,&quot; or &quot;customer satisfaction.&quot; However, these definitions do not offer a method of obtaining quality or a means of relating quality to cost. Taguchi proposes a holistic view of quality which relates quality to cost, not just to the manufacturer at the time of production, but to the customer and society as a whole (Phadke, 1989). Taguchi defines quality as, &quot;The quality of a product is the (minimum) loss imparted by the product to the society from the time product is shipped&quot; (Bryne and Taguchi, 1986). This economic loss is associated with losses due to rework, waste of resources d uring manufacture, warranty costs, customer complaints and dissatisfaction, time and money spent by customers on failing products, and eventual loss of market share.</p>
<p>Figure-1 illustrates the loss function and how it relates to the specification limits. Presented at the 1991 Annual Conference of the International Society of Parametric Analysts. - 2 - LSL USL LOSS $ TARGET Figure-1; The Quadratic Loss Function When a critical quality characteristic deviates from the target value, it causes a loss. In other words, variation from target is the antithesis of quality. Quality simply means no variability or very little variation from target performance (Di Lorenzo, 1990). An examination of the loss function shows that variability reduction or quality improvement drives cost down. Lowest cost can only be achieved at zero variability from target. Continuously pursuing variability reduction from the target value in critical quality characteristics is the key to achieve high quality and reduce cost. Taguchi's quadratic loss function is the first operational joining of cost of quality and variability of product that allows design engineers to actually calculate the optimum design based on cost analysis and experimentation with the design (Teicholz, 1987).</p>
<p>Confirmation is a crucial notion when using Taguchi. Confirmation runs are needed in order to validate analysis success or identify problems with the experiment.</p>
<p>Advantages * Orthogonal arrays reduce number of exprimental runs * Simple calculations * Enabled effect of control and noise factor variation to be optimised</p>
<p>Limitations * Does not deal well with interactions * Not suited to multi-characteristic optimisation * Large number of runs when using noise arrays</p>
<h2 id="design-of-experiments">Design of Experiments</h2>
<p>Design of Experiments (DoE) represents a systematic method to determine the relationship between factors and their interactions to assess how these are affecting the output of that process. It is essentially an approach to determining 'cause and effect' relationships. The DoE method is used to maximize the information obtained from experimental data through very few trials or runs. Four approaches to DoE are listed below:</p>
<ol style="list-style-type: decimal">
<li>Full factorial</li>
<li>Fractional factorial</li>
<li>Taguchi Methods</li>
<li>RSM (Response Surface Methodology)</li>
</ol>
<p>There are typically three components which comprise experimental design. These are detailed below. We take a simplistic example of a cake-baking process to contextualise the DoE approach:</p>
<ul>
<li><strong>Factors</strong> represent the inputs to the process: These can be stipulated as either controllable or uncontrollable variables. In the cake-baking process example these would correspond to the oven and ingredients typically.</li>
<li><strong>Levels</strong> represent the settings of each factors. Typical examples of this in the cake-baking process would be the oven temperature and the ingredient amounts included.</li>
<li><strong>Response</strong> represent the output of the experiment. In the simplistic case of baking a cake these responses could manifest themselves in the form of the taste, consistency and the appearance of the cake. These responses are ultimately affected by the level settings of each factor.</li>
</ul>
<p>The figure below presents the typical DoE approach to baking a cake, highlighting the factors, levels and typical responses.</p>
<div class="figure">
<img src="images/DesignOfExperiments.png" title="Design of Experiments Cake Baking Process" />

</div>
<p>The rationale supporting the cake baking DoE approach is as follows:</p>
<ul>
<li><strong>Comparing ALternatives</strong> - We may want to compare the results from two different types of flour, if it turned out that flour types caused indifferent values, we could purchase from the low cost supplier.</li>
<li><strong>Significant Control Factors</strong> - We may want to determine what the significant factors are.</li>
<li><strong>Optimal Process Output</strong> - Enables determination of the optimal set of factors and corresponding level to achieve the exact taste and consistency.</li>
<li><strong>Reducing Variability</strong> - Can the recipe be changed slightly without detriment to the responses.</li>
<li><strong>Improving Process Robustness</strong> - Improving the fitness for use under varying conditions. For example, can the factors and their levels (recipe) be modified such that cake will come out nearly the same, irrespective of what oven is used.</li>
</ul>
<p>The pertinent benefits of the DoE approach are as follows:</p>
<ol style="list-style-type: decimal">
<li>Quick, economical and efficient method to identify most significant input factors</li>
<li>Simultaneous trials with multiple control factors instead of one variable at a time.</li>
<li>Gives interaction effects of control factors / input factors.</li>
<li>Less number of trials required to get process insight.</li>
<li>Impact of control factors on response can be easily measured.</li>
<li>Explore relationship of response and control factors.</li>
<li>Cheaper than reducing fabrication or simulation bottlenecks.</li>
</ol>
<h2 id="software-process-improvement-tools">Software Process Improvement Tools</h2>
<p>A Software process is defined as the system of all tasks and the supporting tools, standards, methods, and practices involved in the production and evolution of a software product. TQM tools, such as Cause &amp; Effect Diagrams, Pareto Charts and Check Sheets can all be used to improve software processes.</p>
<p>One approach that can be used to improve a business' software process is the PDCA cycle - Plan, Do, Check and Act (The role of Software Process Improvement into Total Quality Management: an Industrial Experience, 2000). This approach can be split up into the following four steps:</p>
<ul>
<li>Planning: involves the reviewing of data and information, establishing and documenting action plans and their deployment in their specific areas</li>
<li>Do: involves the execution of the plans</li>
<li>Check: involves performing reviews in their specific areas, integrating leadership and lower level departments</li>
<li>Act: involves implementing any system changes and the fulfillment of the goals, following the reviews.</li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>Total Quality Management: Text, Cases, and Readings, Third Edition; Joel E. Ross, Susan Perry, 1999</li>
<li>Fundamentals of Total Quality Management; Jens J. Dahlgaard, Kai Kristensen, Gopal K. Kanji, 1998</li>
<li>Total Quality Management as Competitive Advantage: A Review and Empirical Study; Thomas C. Powell, 1995</li>
<li>Total quality management implementation frameworks: Comparison and review; Sha'Ri Mohd Yusof, Elaine Aspinwall, 2000</li>
<li>Multivoting; University of Kentucky, Program and Staff Development, <a href="https://psd.ca.uky.edu/files/multivot.pdf" class="uri">https://psd.ca.uky.edu/files/multivot.pdf</a></li>
<li>Multi-Voting, goLeanSixSigma, <a href="https://goleansixsigma.com/multi-voting/" class="uri">https://goleansixsigma.com/multi-voting/</a></li>
<li>Taguchi Slides, <a href="http://www.slideshare.net/MentariPagi4/tqm-taguchi" class="uri">http://www.slideshare.net/MentariPagi4/tqm-taguchi</a></li>
<li>Taguchi, Teicholz, <a href="http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20040121019.pdf" class="uri">http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20040121019.pdf</a></li>
<li>TQM Software Tools, <a href="http://www.emeraldinsight.com/doi/pdfplus/10.1108/09544789610125333" class="uri">http://www.emeraldinsight.com/doi/pdfplus/10.1108/09544789610125333</a></li>
<li>DoE barriers, <a href="http://www.emeraldinsight.com/doi/pdfplus/10.1108/17542730910995846" class="uri">http://www.emeraldinsight.com/doi/pdfplus/10.1108/17542730910995846</a></li>
<li>ISO 9000 Case Studies, <a href="http://www.bsigroup.com/en-GB/iso-9001-quality-management/case-studies" class="uri">http://www.bsigroup.com/en-GB/iso-9001-quality-management/case-studies</a></li>
<li>The role of software process improvement into total quality management: an industrial experience; R. L. Della Volpe, 2000 Taguchi Orthogonal Arrays: <a href="http://www.york.ac.uk/depts/maths/tables/orthogonal.htm" class="uri">http://www.york.ac.uk/depts/maths/tables/orthogonal.htm</a></li>
</ul>
